## Results

`MessageBatchIndividualResponse Messages.Batches.ResultsStreaming(BatchResultsParamsparameters, CancellationTokencancellationToken = default)`

**get** `/v1/messages/batches/{message_batch_id}/results`

Streams the results of a Message Batch as a `.jsonl` file.

Each line in the file is a JSON object containing the result of a single request in the Message Batch. Results are not guaranteed to be in the same order as requests. Use the `custom_id` field to match results to requests.

Learn more about the Message Batches API in our [user guide](https://docs.claude.com/en/docs/build-with-claude/batch-processing)

### Parameters

- `BatchResultsParams parameters`

  - `required string messageBatchID`

    ID of the Message Batch.

### Returns

- `class MessageBatchIndividualResponse:`

  This is a single line in the response `.jsonl` file and does not represent the response as a whole.

  - `required string CustomID`

    Developer-provided ID created for each request in a Message Batch. Useful for matching results to requests, as results may be given out of request order.

    Must be unique for each request within the Message Batch.

  - `required MessageBatchResult Result`

    Processing result for this request.

    Contains a Message output if processing was successful, an error response if processing failed, or the reason why processing was not attempted, such as cancellation or expiration.

    - `class MessageBatchSucceededResult:`

      - `required Message Message`

        - `required string ID`

          Unique object identifier.

          The format and length of IDs may change over time.

        - `required IReadOnlyList<ContentBlock> Content`

          Content generated by the model.

          This is an array of content blocks, each of which has a `type` that determines its shape.

          Example:

          ```json
          [{"type": "text", "text": "Hi, I'm Claude."}]
          ```

          If the request input `messages` ended with an `assistant` turn, then the response `content` will continue directly from that last turn. You can use this to constrain the model's output.

          For example, if the input `messages` were:

          ```json
          [
            {"role": "user", "content": "What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun"},
            {"role": "assistant", "content": "The best answer is ("}
          ]
          ```

          Then the response `content` might be:

          ```json
          [{"type": "text", "text": "B)"}]
          ```

          - `class TextBlock:`

            - `required IReadOnlyList<TextCitation>? Citations`

              Citations supporting the text block.

              The type of citation returned will depend on the type of document being cited. Citing a PDF results in `page_location`, plain text results in `char_location`, and content document results in `content_block_location`.

              - `class CitationCharLocation:`

                - `required string CitedText`

                - `required Long DocumentIndex`

                - `required string? DocumentTitle`

                - `required Long EndCharIndex`

                - `required string? FileID`

                - `required Long StartCharIndex`

                - `JsonElement Type "char_location"constant`

              - `class CitationPageLocation:`

                - `required string CitedText`

                - `required Long DocumentIndex`

                - `required string? DocumentTitle`

                - `required Long EndPageNumber`

                - `required string? FileID`

                - `required Long StartPageNumber`

                - `JsonElement Type "page_location"constant`

              - `class CitationContentBlockLocation:`

                - `required string CitedText`

                - `required Long DocumentIndex`

                - `required string? DocumentTitle`

                - `required Long EndBlockIndex`

                - `required string? FileID`

                - `required Long StartBlockIndex`

                - `JsonElement Type "content_block_location"constant`

              - `class CitationsWebSearchResultLocation:`

                - `required string CitedText`

                - `required string EncryptedIndex`

                - `required string? Title`

                - `JsonElement Type "web_search_result_location"constant`

                - `required string Url`

              - `class CitationsSearchResultLocation:`

                - `required string CitedText`

                - `required Long EndBlockIndex`

                - `required Long SearchResultIndex`

                - `required string Source`

                - `required Long StartBlockIndex`

                - `required string? Title`

                - `JsonElement Type "search_result_location"constant`

            - `required string Text`

            - `JsonElement Type "text"constant`

          - `class ThinkingBlock:`

            - `required string Signature`

            - `required string Thinking`

            - `JsonElement Type "thinking"constant`

          - `class RedactedThinkingBlock:`

            - `required string Data`

            - `JsonElement Type "redacted_thinking"constant`

          - `class ToolUseBlock:`

            - `required string ID`

            - `required IReadOnlyDictionary<string, JsonElement> Input`

            - `required string Name`

            - `JsonElement Type "tool_use"constant`

          - `class ServerToolUseBlock:`

            - `required string ID`

            - `required IReadOnlyDictionary<string, JsonElement> Input`

            - `JsonElement Name "web_search"constant`

            - `JsonElement Type "server_tool_use"constant`

          - `class WebSearchToolResultBlock:`

            - `required WebSearchToolResultBlockContent Content`

              - `class WebSearchToolResultError:`

                - `required ErrorCode ErrorCode`

                  - `"invalid_tool_input"InvalidToolInput`

                  - `"unavailable"Unavailable`

                  - `"max_uses_exceeded"MaxUsesExceeded`

                  - `"too_many_requests"TooManyRequests`

                  - `"query_too_long"QueryTooLong`

                  - `"request_too_large"RequestTooLarge`

                - `JsonElement Type "web_search_tool_result_error"constant`

              - `IReadOnlyList<WebSearchResultBlock>`

                - `required string EncryptedContent`

                - `required string? PageAge`

                - `required string Title`

                - `JsonElement Type "web_search_result"constant`

                - `required string Url`

            - `required string ToolUseID`

            - `JsonElement Type "web_search_tool_result"constant`

        - `required Model Model`

          The model that will complete your prompt.

          See [models](https://docs.anthropic.com/en/docs/models-overview) for additional details and options.

          - `"claude-opus-4-6"ClaudeOpus4_6`

            Most intelligent model for building agents and coding

          - `"claude-opus-4-5-20251101"ClaudeOpus4_5_20251101`

            Premium model combining maximum intelligence with practical performance

          - `"claude-opus-4-5"ClaudeOpus4_5`

            Premium model combining maximum intelligence with practical performance

          - `"claude-3-7-sonnet-latest"Claude3_7SonnetLatest`

            High-performance model with early extended thinking

          - `"claude-3-7-sonnet-20250219"Claude3_7Sonnet20250219`

            High-performance model with early extended thinking

          - `"claude-3-5-haiku-latest"Claude3_5HaikuLatest`

            Fastest and most compact model for near-instant responsiveness

          - `"claude-3-5-haiku-20241022"Claude3_5Haiku20241022`

            Our fastest model

          - `"claude-haiku-4-5"ClaudeHaiku4_5`

            Hybrid model, capable of near-instant responses and extended thinking

          - `"claude-haiku-4-5-20251001"ClaudeHaiku4_5_20251001`

            Hybrid model, capable of near-instant responses and extended thinking

          - `"claude-sonnet-4-20250514"ClaudeSonnet4_20250514`

            High-performance model with extended thinking

          - `"claude-sonnet-4-0"ClaudeSonnet4_0`

            High-performance model with extended thinking

          - `"claude-4-sonnet-20250514"Claude4Sonnet20250514`

            High-performance model with extended thinking

          - `"claude-sonnet-4-5"ClaudeSonnet4_5`

            Our best model for real-world agents and coding

          - `"claude-sonnet-4-5-20250929"ClaudeSonnet4_5_20250929`

            Our best model for real-world agents and coding

          - `"claude-opus-4-0"ClaudeOpus4_0`

            Our most capable model

          - `"claude-opus-4-20250514"ClaudeOpus4_20250514`

            Our most capable model

          - `"claude-4-opus-20250514"Claude4Opus20250514`

            Our most capable model

          - `"claude-opus-4-1-20250805"ClaudeOpus4_1_20250805`

            Our most capable model

          - `"claude-3-opus-latest"Claude3OpusLatest`

            Excels at writing and complex tasks

          - `"claude-3-opus-20240229"Claude_3_Opus_20240229`

            Excels at writing and complex tasks

          - `"claude-3-haiku-20240307"Claude_3_Haiku_20240307`

            Our previous most fast and cost-effective

        - `JsonElement Role "assistant"constant`

          Conversational role of the generated message.

          This will always be `"assistant"`.

        - `required StopReason? StopReason`

          The reason that we stopped.

          This may be one the following values:

          * `"end_turn"`: the model reached a natural stopping point
          * `"max_tokens"`: we exceeded the requested `max_tokens` or the model's maximum
          * `"stop_sequence"`: one of your provided custom `stop_sequences` was generated
          * `"tool_use"`: the model invoked one or more tools
          * `"pause_turn"`: we paused a long-running turn. You may provide the response back as-is in a subsequent request to let the model continue.
          * `"refusal"`: when streaming classifiers intervene to handle potential policy violations

          In non-streaming mode this value is always non-null. In streaming mode, it is null in the `message_start` event and non-null otherwise.

          - `"end_turn"EndTurn`

          - `"max_tokens"MaxTokens`

          - `"stop_sequence"StopSequence`

          - `"tool_use"ToolUse`

          - `"pause_turn"PauseTurn`

          - `"refusal"Refusal`

        - `required string? StopSequence`

          Which custom stop sequence was generated, if any.

          This value will be a non-null string if one of your custom stop sequences was generated.

        - `JsonElement Type "message"constant`

          Object type.

          For Messages, this is always `"message"`.

        - `required Usage Usage`

          Billing and rate-limit usage.

          Anthropic's API bills and rate-limits by token counts, as tokens represent the underlying cost to our systems.

          Under the hood, the API transforms requests into a format suitable for the model. The model's output then goes through a parsing stage before becoming an API response. As a result, the token counts in `usage` will not match one-to-one with the exact visible content of an API request or response.

          For example, `output_tokens` will be non-zero, even for an empty string response from Claude.

          Total input tokens in a request is the summation of `input_tokens`, `cache_creation_input_tokens`, and `cache_read_input_tokens`.

          - `required CacheCreation? CacheCreation`

            Breakdown of cached tokens by TTL

            - `required Long Ephemeral1hInputTokens`

              The number of input tokens used to create the 1 hour cache entry.

            - `required Long Ephemeral5mInputTokens`

              The number of input tokens used to create the 5 minute cache entry.

          - `required Long? CacheCreationInputTokens`

            The number of input tokens used to create the cache entry.

          - `required Long? CacheReadInputTokens`

            The number of input tokens read from the cache.

          - `required string? InferenceGeo`

            The geographic region where inference was performed for this request.

          - `required Long InputTokens`

            The number of input tokens which were used.

          - `required Long OutputTokens`

            The number of output tokens which were used.

          - `required ServerToolUsage? ServerToolUse`

            The number of server tool requests.

            - `required Long WebSearchRequests`

              The number of web search tool requests.

          - `required ServiceTier? ServiceTier`

            If the request used the priority, standard, or batch tier.

            - `"standard"Standard`

            - `"priority"Priority`

            - `"batch"Batch`

      - `JsonElement Type "succeeded"constant`

    - `class MessageBatchErroredResult:`

      - `required ErrorResponse Error`

        - `required ErrorObject Error`

          - `class InvalidRequestError:`

            - `required string Message`

            - `JsonElement Type "invalid_request_error"constant`

          - `class AuthenticationError:`

            - `required string Message`

            - `JsonElement Type "authentication_error"constant`

          - `class BillingError:`

            - `required string Message`

            - `JsonElement Type "billing_error"constant`

          - `class PermissionError:`

            - `required string Message`

            - `JsonElement Type "permission_error"constant`

          - `class NotFoundError:`

            - `required string Message`

            - `JsonElement Type "not_found_error"constant`

          - `class RateLimitError:`

            - `required string Message`

            - `JsonElement Type "rate_limit_error"constant`

          - `class GatewayTimeoutError:`

            - `required string Message`

            - `JsonElement Type "timeout_error"constant`

          - `class ApiErrorObject:`

            - `required string Message`

            - `JsonElement Type "api_error"constant`

          - `class OverloadedError:`

            - `required string Message`

            - `JsonElement Type "overloaded_error"constant`

        - `required string? RequestID`

        - `JsonElement Type "error"constant`

      - `JsonElement Type "errored"constant`

    - `class MessageBatchCanceledResult:`

      - `JsonElement Type "canceled"constant`

    - `class MessageBatchExpiredResult:`

      - `JsonElement Type "expired"constant`
